\section{Related Work}

	The demand for applications which address issues facing e-Science has grown dramatically in recent years. Several workflow tools have been developed to address this demand. Discovery Net \cite{discoNet} was one of the first tools available to coordinate the execution of remote services using the web. It provides a means to coordinate workflows between data owners and analysis servers that may be far-flung geographically. The system also allowed for visual coding through a drag and drop interface. Although the Discovery Net project was quick to recognize the need for workflow coordination services,  their XML based language known as 'Discovery Markup Language' in addition to its domain specific nature and high cost of integration into existing projects did not allow for widespread adoption. 	
	Taverna Workbench \cite{taverna} is an open source tool that has emerged with a graphical focus; using a limited drag and drop functionality, users can construct a workflow with representations for inputs, outputs and various services. The application facilitates the building, execution, and collaboration of workflows through web services. The interface provides a services tab to associate graphical blocks with analytical functions, and a standard project hierarchy navigator. Coined as an 'enactment engine,' Taverna's integration with popular programming languages is difficult. Additionally, users quickly find themselves lost in a maze of drop down windows. 
	
	Kepler \cite{kepler} is another open source GUI based workflow tool being developed as a joint project between multiple University of California campuses. It offers support for various grid services and has the ability to execute workflows from a command line or graphical interface. Like Taverna, however,  Kepler's main drawback is its loose association with C or Python. Instead, it uses a host of pre made components for statistical analysis. 
	
	Triana's \cite{triana} take on workflow development was to formulate a 'pluggable architecture' that can integrate into existing systems. It comes with a variety of built in tools for signal analysis as well as image manipulation. Triana has basic error detection, but no support for handling errors during parallel failures during a join stage. Again, the drawback of this tool is the user is confined to using a set of pre-made functions. If a custom function is desired, it must be specified in a wizard provided by the application. 
	
	The concept for Pegasus \cite{pegasus} is interesting in its divergence from the others. Instead of the typical graphical focus, Pegasus' focus is on being able to execute on a wide variety of distributed environments including clusters, grids and clouds. Pegasus has the ability to map elements of a given workflow to available resources on the target environment. Pegasus offers a GUI, but goes so far as to include a disclaimer on their site which reads, "It is a demonstration tool and can be used to see how simple DAXes look like. However, to generate your workflows, we recommend to use the various APIs we provide." The broad class of computational patterns (DAXes) that Pegasus supports makes the API powerful, but non-trivial to learn or use. 
	
	Within these projects, there is little support for automatic scaling to fit growing datasets. Further, the problems of fault tolerance  and dynamic workflow execution remain. Focus on exotic computation patterns or specialized syntax often makes for confusing APIs and limited usability. 
	
	
\label{sec:related} 
